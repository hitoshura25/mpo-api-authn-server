# Extract VulnerabilityCategorizor & Eliminate Categorization Duplication

## **Problem Statement**

The security vulnerability categorization logic is currently embedded within `enhanced_dataset_creator.py`, causing duplication and architectural issues:

1. **Duplication Risk**: Categorization logic may be duplicated across phases
2. **Tight Coupling**: EnhancedDatasetCreator handles both categorization AND dataset creation
3. **Stage 2 Validation Failure**: Training phase uses uncategorized vulnerabilities from Phase 3, while categorization happens in Phase 4
4. **No Fail-Fast**: 'unknown' categories are silently accepted, causing failures hours later

## **Root Cause Analysis**

**Current Flow:**
1. **Phase 1-3**: Raw vulnerabilities ‚Üí parsed ‚Üí analyzed ‚Üí narrativized (NO categories)
2. **Phase 4**: Enhanced dataset creation ‚Üí categorizes vulnerabilities (categories added here)
3. **Phase 5**: Training uses narrativized results (NO categories) ‚Üí Stage 2 validation fails with 0.00 score

**Issue**: Training phase (Phase 5) uses data from Phase 3, but categorization happens in Phase 4, creating a data flow mismatch.

## **Solution Architecture**

### **1. Extract VulnerabilityCategorizor into Standalone Module**

Create `vulnerability_categorizer.py` as a dedicated categorization service used across multiple phases.

### **2. Move Categorization to Phase 2C (Analysis Summary)**

Phase 2C is the natural place for vulnerability enrichment after analysis aggregation. This ensures all downstream phases receive categorized data.

### **3. Implement Fail-Fast Behavior**

Replace all 'unknown' fallbacks with immediate failures to catch categorization issues early.

### **4. Update EnhancedDatasetCreator**

Remove categorization logic and expect pre-categorized vulnerabilities as input.

## **Detailed Implementation Plan**

### **STEP 1: Create Standalone Categorization Module**

**File**: `vulnerability_categorizer.py`

```python
#!/usr/bin/env python3
"""
Vulnerability Categorizer - Security Domain Classification

Standalone module for categorizing vulnerabilities by security domain.
Used across multiple phases to ensure consistent categorization.
"""

import logging
from typing import Dict, Any, Tuple


class VulnerabilityCategorizor:
    """Categorizes vulnerabilities by security domain for specialized training."""

    def __init__(self):
        self.logger = logging.getLogger(__name__)

        # Tool-to-category mapping based on security scanner origin
        self.tool_category_map = {
            # Container Security
            'sarif-trivy': 'container_security',
            'trivy': 'container_security',

            # Infrastructure Security
            'sarif-checkov': 'infrastructure_security',
            'checkov': 'infrastructure_security',
            'sarif-gitleaks': 'infrastructure_security',
            'gitleaks': 'infrastructure_security',

            # Web Security
            'zap': 'web_security',
            'sarif-zap': 'web_security',

            # Dependency Vulnerabilities
            'osv-scanner': 'dependency_vulnerabilities',
            'sarif-osv': 'dependency_vulnerabilities',

            # Code Vulnerabilities & WebAuthn
            'semgrep': 'code_vulnerabilities',  # Default, refined by content analysis
            'sarif-semgrep': 'code_vulnerabilities',

            # Mobile Security (if applicable)
            'mobsf': 'mobile_security',
        }

        # WebAuthn-specific patterns for semgrep refinement
        self.webauthn_patterns = [
            'webauthn', 'fido', 'authenticator', 'credential',
            'attestation', 'assertion', 'challenge', 'passkey'
        ]

    def categorize_vulnerability(self, vulnerability: Dict[str, Any]) -> Tuple[str, float]:
        """
        Categorize vulnerability by security domain.

        Args:
            vulnerability: Vulnerability data with tool, description, file_path etc.

        Returns:
            Tuple of (category, confidence_score)

        Raises:
            ValueError: If tool is unknown (fail-fast behavior)
        """
        tool = vulnerability.get('tool', '').lower()
        vuln_id = vulnerability.get('id', 'unknown')

        # ‚úÖ FAIL-FAST: No unknown tools allowed
        if not tool:
            raise ValueError(f"Vulnerability {vuln_id} missing 'tool' field. Cannot categorize.")

        if tool not in self.tool_category_map:
            supported_tools = list(self.tool_category_map.keys())
            raise ValueError(f"Unknown security tool '{tool}' for vulnerability {vuln_id}. "
                           f"Cannot categorize - pipeline must stop. "
                           f"Supported tools: {supported_tools}")

        # Get base category from tool mapping
        base_category = self.tool_category_map[tool]

        # Special handling for semgrep - check for WebAuthn patterns
        if base_category == 'code_vulnerabilities':
            webauthn_category, webauthn_confidence = self._check_webauthn_patterns(vulnerability)
            if webauthn_category:
                return webauthn_category, webauthn_confidence

        # Calculate confidence for base category
        confidence = self._calculate_confidence(vulnerability, base_category)

        return base_category, confidence

    def _check_webauthn_patterns(self, vulnerability: Dict[str, Any]) -> Tuple[str, float]:
        """Check if code vulnerability is WebAuthn-specific."""
        text_content = ' '.join([
            vulnerability.get('description', ''),
            vulnerability.get('message', ''),
            vulnerability.get('file_path', ''),
            str(vulnerability.get('metadata', {}))
        ]).lower()

        webauthn_matches = sum(1 for pattern in self.webauthn_patterns
                              if pattern in text_content)

        if webauthn_matches >= 2:  # Strong WebAuthn indication
            return 'webauthn_security', 0.8 + (webauthn_matches * 0.05)
        elif webauthn_matches == 1:  # Possible WebAuthn
            return 'webauthn_security', 0.6

        return None, 0.0

    def _calculate_confidence(self, vulnerability: Dict[str, Any], category: str) -> float:
        """Calculate confidence score for categorization."""
        confidence = 0.7  # Base confidence

        # Tool-specific confidence adjustments
        tool = vulnerability.get('tool', '').lower()

        # High confidence tools
        if tool in ['sarif-trivy', 'sarif-checkov', 'osv-scanner']:
            confidence = 0.9

        # Medium confidence tools
        elif tool in ['zap', 'gitleaks']:
            confidence = 0.8

        # Adjust based on content richness
        description = vulnerability.get('description', '')
        if len(description) > 100:
            confidence += 0.05

        if vulnerability.get('severity') in ['HIGH', 'CRITICAL', 'high', 'critical']:
            confidence += 0.05

        return min(confidence, 1.0)
```

### **STEP 2: Update Enhanced Dataset Creator**

**File**: `enhanced_dataset_creator.py`

**Changes:**

1. **Remove VulnerabilityCategorizor class definition** (moved to separate file)
2. **Import from new module**: `from vulnerability_categorizer import VulnerabilityCategorizor`
3. **Remove categorization logic** from `create_enhanced_dataset()`
4. **Add validation** that input vulnerabilities have `security_category`

```python
# At top of file - UPDATE IMPORTS
from vulnerability_categorizer import VulnerabilityCategorizor

class EnhancedDatasetCreator:
    def create_enhanced_dataset(self, vulnerabilities: List[Dict[str, Any]],
                              dataset_name: Optional[str] = None) -> DatasetCreationResult:
        """
        Create enhanced dataset from PRE-CATEGORIZED vulnerabilities.

        IMPORTANT: This method expects vulnerabilities to already have 'security_category'
        field assigned by earlier phases. Categorization is no longer done here.
        """

        # ‚úÖ VALIDATE: All vulnerabilities must have security_category
        for vuln in vulnerabilities:
            vuln_id = vuln.get('id', 'unknown')

            if 'security_category' not in vuln:
                raise ValueError(f"Vulnerability {vuln_id} missing 'security_category' field. "
                               f"Categorization must happen in Phase 2C before dataset creation. "
                               f"Pipeline data flow error.")

            if vuln.get('security_category') == 'unknown':
                raise ValueError(f"Vulnerability {vuln_id} has 'unknown' security_category. "
                               f"This should have been caught during categorization phase. "
                               f"Pipeline fail-fast validation failure.")

        # ‚úÖ PROCEED: Use existing categories for processing
        category_counts = {}
        processed_count = 0
        failed_count = 0

        final_examples = []

        try:
            for vuln in vulnerabilities:
                # Count categories (no re-categorization)
                category = vuln['security_category']
                category_counts[category] = category_counts.get(category, 0) + 1

                # ... rest of existing dataset creation logic ...
                # (extract context, generate fixes, create examples)

        # ... rest of method unchanged ...
```

### **STEP 3: Add Categorization to Phase 2C**

**File**: `process_artifacts.py`

**Method**: `analysis_summary_phase()`

```python
def analysis_summary_phase(rag_enhanced_file, output_dir, args):
    """
    Phase 2C: Analysis Summary + Security Categorization

    This phase now handles both analysis aggregation AND security categorization
    to ensure all downstream phases receive properly categorized vulnerabilities.
    """

    # ... existing analysis aggregation logic ...

    # ‚úÖ NEW: Add security categorization after analysis
    print("üè∑Ô∏è Adding security categorization to analyzed vulnerabilities...")

    from vulnerability_categorizer import VulnerabilityCategorizor
    categorizer = VulnerabilityCategorizor()

    category_counts = {}
    categorized_count = 0

    for item in analyzed_vulnerabilities:
        if item.get('status') == 'success':
            vuln = item.get('vulnerability', {})
            vuln_id = vuln.get('id', 'unknown')

            try:
                category, confidence = categorizer.categorize_vulnerability(vuln)

                # Add categorization to vulnerability
                vuln['security_category'] = category
                vuln['category_confidence'] = confidence

                # Track distribution
                category_counts[category] = category_counts.get(category, 0) + 1
                categorized_count += 1

                self.logger.debug(f"‚úÖ Categorized {vuln_id}: {category} (confidence: {confidence:.2f})")

            except ValueError as e:
                # ‚úÖ FAIL-FAST: Stop pipeline on categorization failure
                print(f"‚ùå CRITICAL: Categorization failed in Phase 2C")
                print(f"   Vulnerability: {vuln_id}")
                print(f"   Error: {e}")
                raise RuntimeError(f"Critical categorization failure in Phase 2C: {e}") from e

    print(f"‚úÖ Successfully categorized {categorized_count} vulnerabilities")
    print(f"   üìä Category distribution: {category_counts}")

    # Validate categorization completeness
    total_success = len([item for item in analyzed_vulnerabilities
                        if item.get('status') == 'success'])

    if categorized_count != total_success:
        raise RuntimeError(f"Categorization incomplete: {categorized_count}/{total_success} vulnerabilities categorized")

    # ... save and return logic unchanged ...
    return analyzed_vulnerabilities, analysis_file, analysis_summary_file
```

### **STEP 4: Add Phase Boundary Validations**

**File**: `process_artifacts.py`

Add validation functions to ensure security_category propagates correctly:

```python
def validate_phase_has_categories(vulnerabilities: List[Dict], phase_name: str) -> None:
    """Validate that all vulnerabilities have security_category field."""

    for item in vulnerabilities:
        if item.get('status') == 'success':
            vuln = item.get('vulnerability', {})
            vuln_id = vuln.get('id', 'unknown')

            if 'security_category' not in vuln:
                raise RuntimeError(f"{phase_name} input validation failed: "
                                 f"Vulnerability {vuln_id} missing security_category. "
                                 f"Phase 2C categorization may have failed.")

            if vuln.get('security_category') == 'unknown':
                raise RuntimeError(f"{phase_name} input validation failed: "
                                 f"Vulnerability {vuln_id} has unknown category. "
                                 f"This should have been caught in Phase 2C.")

# Update phase functions to include validation
def narrativization_phase(analyzed_file, output_dir, args):
    """Phase 3: Narrativization with category validation."""

    # Load analyzed vulnerabilities
    with open(analyzed_file, 'r') as f:
        analyzed_results = json.load(f)

    # ‚úÖ VALIDATE: Input has categories
    validate_phase_has_categories(analyzed_results, "Phase 3 (Narrativization)")

    # ... rest of narrativization logic unchanged ...

def training_phase(train_file, train_data, narrativized_results, analysis_summary, args):
    """Phase 5: Training with category validation."""

    # ‚úÖ VALIDATE: Input has categories
    validate_phase_has_categories(narrativized_results, "Phase 5 (Training)")

    # ... rest of training logic unchanged ...
```

### **STEP 5: Add Comprehensive Testing**

**New File**: `tests/unit/test_vulnerability_categorizer.py`

```python
#!/usr/bin/env python3
"""Unit tests for VulnerabilityCategorizor."""

import pytest
import sys
from pathlib import Path

# Add project root to path
sys.path.insert(0, str(Path(__file__).parent.parent.parent))

from vulnerability_categorizer import VulnerabilityCategorizor


class TestVulnerabilityCategorizor:

    def setup_method(self):
        self.categorizer = VulnerabilityCategorizor()

    def test_container_security_categorization(self):
        """Test container security tool categorization."""
        vuln = {
            'tool': 'sarif-trivy',
            'id': 'CVE-2024-1234',
            'description': 'Container vulnerability in base image'
        }

        category, confidence = self.categorizer.categorize_vulnerability(vuln)

        assert category == 'container_security'
        assert confidence > 0.7

    def test_webauthn_security_categorization(self):
        """Test WebAuthn-specific categorization."""
        vuln = {
            'tool': 'semgrep',
            'id': 'WEBAUTHN-001',
            'description': 'WebAuthn credential validation missing',
            'file_path': '/src/webauthn/authenticator.js'
        }

        category, confidence = self.categorizer.categorize_vulnerability(vuln)

        assert category == 'webauthn_security'
        assert confidence > 0.6

    def test_fail_fast_unknown_tool(self):
        """Test fail-fast behavior on unknown tools."""
        vuln = {
            'tool': 'unknown-scanner',
            'id': 'TEST-001',
            'description': 'Test vulnerability'
        }

        with pytest.raises(ValueError, match="Unknown security tool"):
            self.categorizer.categorize_vulnerability(vuln)

    def test_fail_fast_missing_tool(self):
        """Test fail-fast behavior on missing tool field."""
        vuln = {
            'id': 'TEST-002',
            'description': 'Test vulnerability'
            # Missing 'tool' field
        }

        with pytest.raises(ValueError, match="missing 'tool' field"):
            self.categorizer.categorize_vulnerability(vuln)

    def test_all_supported_tools(self):
        """Test that all supported tools can be categorized."""
        supported_tools = [
            'sarif-trivy', 'trivy', 'sarif-checkov', 'checkov',
            'sarif-gitleaks', 'gitleaks', 'zap', 'osv-scanner',
            'semgrep', 'sarif-semgrep'
        ]

        for tool in supported_tools:
            vuln = {'tool': tool, 'id': f'TEST-{tool}', 'description': 'Test'}
            category, confidence = self.categorizer.categorize_vulnerability(vuln)

            assert category in [
                'container_security', 'infrastructure_security',
                'web_security', 'dependency_vulnerabilities',
                'code_vulnerabilities', 'webauthn_security'
            ]
            assert 0.0 < confidence <= 1.0


if __name__ == '__main__':
    pytest.main([__file__])
```

**Update File**: `tests/integration/test_process_artifacts_script.py`

```python
def test_phase_outputs_have_security_categories(self):
    """Verify all phases after 2C have security_category fields."""

    # Test Phase 2C output (analyzed vulnerabilities with categories)
    analyzed_file = self.get_latest_phase_file("analyzed")
    with open(analyzed_file, 'r') as f:
        analyzed_results = json.load(f)

    successful_analyzed = [r for r in analyzed_results if r.get('status') == 'success']
    assert len(successful_analyzed) > 0, "Should have successful analyzed results"

    for item in successful_analyzed:
        vuln = item.get('vulnerability', {})
        vuln_id = vuln.get('id', 'unknown')

        assert 'security_category' in vuln, f"Missing security_category in {vuln_id}"
        assert vuln['security_category'] != 'unknown', f"Unknown category in {vuln_id}"
        assert 'category_confidence' in vuln, f"Missing category_confidence in {vuln_id}"

    # Test Phase 3 output (narrativized vulnerabilities preserve categories)
    narrativized_file = self.get_latest_phase_file("narrativized")
    with open(narrativized_file, 'r') as f:
        narrativized_results = json.load(f)

    for vuln in narrativized_results:
        vuln_id = vuln.get('id', 'unknown')
        assert 'security_category' in vuln, f"Missing security_category in narrativized {vuln_id}"
        assert vuln['security_category'] != 'unknown', f"Unknown category in narrativized {vuln_id}"

def test_enhanced_dataset_creator_expects_categories(self):
    """Test that EnhancedDatasetCreator validates pre-categorized input."""
    from enhanced_dataset_creator import EnhancedDatasetCreator

    creator = EnhancedDatasetCreator()

    # Should fail with uncategorized vulnerabilities
    uncategorized_vulns = [
        {
            'id': 'TEST-001',
            'tool': 'trivy',
            'description': 'Test vulnerability'
            # Missing security_category
        }
    ]

    with pytest.raises(ValueError, match="missing 'security_category'"):
        creator.create_enhanced_dataset(uncategorized_vulns)

    # Should fail with unknown categories
    unknown_category_vulns = [
        {
            'id': 'TEST-002',
            'tool': 'trivy',
            'description': 'Test vulnerability',
            'security_category': 'unknown'  # Should have been caught earlier
        }
    ]

    with pytest.raises(ValueError, match="'unknown' security_category"):
        creator.create_enhanced_dataset(unknown_category_vulns)

def test_fail_fast_categorization_in_pipeline(self):
    """Test that pipeline fails fast on unknown tools."""

    # This would require creating test data with unknown tools
    # and verifying the pipeline stops in Phase 2C
    # Implementation depends on existing test infrastructure
    pass
```

## **Implementation Checklist**

### **Phase 1: Extract & Setup**
- [ ] Create `vulnerability_categorizer.py` with complete VulnerabilityCategorizor class
- [ ] Update `enhanced_dataset_creator.py` imports
- [ ] Remove VulnerabilityCategorizor class from `enhanced_dataset_creator.py`
- [ ] Add input validation to EnhancedDatasetCreator.create_enhanced_dataset()

### **Phase 2: Move Categorization**
- [ ] Add categorization logic to `analysis_summary_phase()` in `process_artifacts.py`
- [ ] Add phase boundary validation functions
- [ ] Update narrativization_phase() to validate input categories
- [ ] Update training_phase() to validate input categories

### **Phase 3: Testing**
- [ ] Create `tests/unit/test_vulnerability_categorizer.py`
- [ ] Add categorization tests to `test_process_artifacts_script.py`
- [ ] Update any existing tests that import VulnerabilityCategorizor
- [ ] Run unit tests: `./run_tests.sh quick`
- [ ] Run integration tests: `./run_tests.sh integration`

### **Phase 4: Validation**
- [ ] Run complete pipeline: `python process_artifacts.py --artifacts-dir data/security_artifacts --output-dir output`
- [ ] Verify Stage 2 validation passes (should score > 0.7)
- [ ] Test fail-fast behavior with unknown tool data
- [ ] Verify no categorization duplication in logs

## **Success Criteria**

1. **‚úÖ No Duplication**: VulnerabilityCategorizor exists only in `vulnerability_categorizer.py`
2. **‚úÖ Fail-Fast**: Pipeline stops immediately on unknown tools in Phase 2C
3. **‚úÖ Proper Flow**: All phases after 2C have security_category fields
4. **‚úÖ Stage 2 Success**: Training validation passes with categorized vulnerabilities
5. **‚úÖ Test Coverage**: Comprehensive tests validate categorization at every boundary

## **Risk Mitigation**

1. **Backup**: Create git branch before starting implementation
2. **Incremental**: Test each phase independently before moving to next
3. **Rollback Plan**: If issues arise, can temporarily add categorization back to training phase
4. **Validation**: Use existing working test script to verify Stage 2 model works

## **Files Modified Summary**

**New Files:**
- `vulnerability_categorizer.py`
- `tests/unit/test_vulnerability_categorizer.py`

**Modified Files:**
- `enhanced_dataset_creator.py` (remove categorization, add validation)
- `process_artifacts.py` (add categorization to Phase 2C, add validations)
- `tests/integration/test_process_artifacts_script.py` (add category tests)
- Any existing tests importing VulnerabilityCategorizor

This implementation eliminates categorization duplication while ensuring robust fail-fast behavior and comprehensive testing coverage.