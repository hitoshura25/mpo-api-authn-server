# E2E Tests Orchestrator - Cross-Platform Integration
#
# This workflow orchestrates comprehensive end-to-end tests using built Docker images
# to ensure full system integration works correctly across all platforms.
#
# ARCHITECTURE:
# - Orchestrates parallel execution of platform-specific E2E workflows
# - Web E2E: Delegates to web-e2e-tests.yml (Playwright testing)
# - Android E2E: Delegates to android-e2e-tests.yml (emulator testing)
# - Results aggregation: Collects and reports results from both platforms
#
# TRIGGER CONDITIONS:
# - Called by main orchestrator workflow (main-ci-cd.yml)
# - Only runs when Docker images have been successfully built
# - Uses the exact images that were built for the PR
#
# TEST COVERAGE:
# - Cross-platform WebAuthn functionality (Android + Web)
# - Full API contract validation
# - Integration between all services
# - Real Docker image validation
#
# BENEFITS:
# - True parallel execution of platform tests
# - Independent platform team ownership
# - Selective test execution capabilities
# - Improved maintainability and specialization

name: E2E Tests - Cross-Platform Orchestrator

on:
  workflow_call:
    inputs:
      webauthn_server_image:
        description: 'WebAuthn server Docker image tag'
        required: true
        type: string
      test_credentials_image:
        description: 'Test credentials service Docker image tag'
        required: true
        type: string
      workflow-identifier:
        description: 'Workflow identifier for artifact naming (PR number or fallback value for main branch)'
        required: false
        type: string
        default: ''
      # Component change detection inputs for smart E2E triggering
      webauthn-server-changed:
        description: 'Whether webauthn-server component changed'
        required: false
        default: 'false'
        type: string
      test-credentials-service-changed:
        description: 'Whether test-credentials-service component changed'
        required: false
        default: 'false'
        type: string
      openapi-changed:
        description: 'Whether OpenAPI specification changed'
        required: false
        default: 'false'
        type: string
      e2e-tests-changed:
        description: 'Whether E2E test files changed'
        required: false
        default: 'false'
        type: string

env:
  ANDROID_API_VERSION: "29"
  JAVA_VERSION: "21"
  # Use workflow inputs directly
  WORKFLOW_IDENTIFIER: ${{ github.event.pull_request.number || github.run_number || 'main' }}
  WEBAUTHN_SERVER_IMAGE: ${{ inputs.webauthn_server_image }}
  TEST_CREDENTIALS_IMAGE: ${{ inputs.test_credentials_image }}
  BASE_VERSION: "1.0"
  PUBLISHING_CONFIG_FILE: "config/publishing-config.yml"

jobs:
  # Job 1: Setup configuration for callable workflows (convert env vars to job outputs)
  setup-config:
    runs-on: ubuntu-latest
    outputs:
      java-version: ${{ steps.config.outputs.java-version }}
      android-api-version: ${{ steps.config.outputs.android-api-version }}
      docker-registry: ${{ steps.config.outputs.docker-registry }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      - name: Load configuration from central config file
        id: config
        run: |
          echo "ðŸ”§ Loading configuration from ${{ env.PUBLISHING_CONFIG_FILE }}..."

          # Load configuration (yq is pre-installed on GitHub runners)
          CONFIG_FILE="${{ env.PUBLISHING_CONFIG_FILE }}"

          # Validate configuration file exists
          if [ ! -f "$CONFIG_FILE" ]; then
            echo "âŒ Configuration file not found: $CONFIG_FILE"
            exit 1
          fi

          # Extract configuration values (E2E tests use staging environment)
          DOCKER_REGISTRY=$(yq '.docker.registry.url' "$CONFIG_FILE")

          # Validate required values are not null
          if [ "$DOCKER_REGISTRY" = "null" ]; then
            echo "âŒ Missing required configuration in $CONFIG_FILE"
            echo "Docker registry: $DOCKER_REGISTRY"
            exit 1
          fi

          # Set outputs (mix of central config and environment variables)
          echo "java-version=${{ env.JAVA_VERSION }}" >> $GITHUB_OUTPUT
          echo "android-api-version=${{ env.ANDROID_API_VERSION }}" >> $GITHUB_OUTPUT
          echo "docker-registry=$DOCKER_REGISTRY" >> $GITHUB_OUTPUT

          echo "âœ… Configuration loaded successfully:"
          echo "  Docker registry: $DOCKER_REGISTRY (from central config)"
          echo "  Java version: ${{ env.JAVA_VERSION }} (from environment)"

  # Job 2: Component-aware E2E test orchestration with intelligent scope determination
  analyze-e2e-requirements:
    runs-on: ubuntu-latest
    needs: setup-config
    outputs:
      web-cache-hit: ${{ steps.web-cache.outputs.cache-hit }}
      android-cache-hit: ${{ steps.android-cache.outputs.cache-hit }}
      cache-key-web: ${{ steps.cache-keys.outputs.web-key }}
      cache-key-android: ${{ steps.cache-keys.outputs.android-key }}
      skip-web-e2e: ${{ steps.determine-scope.outputs.skip-web-e2e }}
      skip-android-e2e: ${{ steps.determine-scope.outputs.skip-android-e2e }}
      should-run-web-e2e: ${{ steps.determine-scope.outputs.should-run-web-e2e }}
      should-run-android-e2e: ${{ steps.determine-scope.outputs.should-run-android-e2e }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Generate E2E cache keys
        id: cache-keys
        run: |
          # Extract image tags for cache key (use full tag, not digest)
          WEBAUTHN_IMAGE_TAG="${{ inputs.webauthn_server_image }}"
          TEST_CREDS_IMAGE_TAG="${{ inputs.test_credentials_image }}"

          # Create hash-friendly versions of image tags (replace problematic characters)
          WEBAUTHN_TAG_HASH=$(echo "$WEBAUTHN_IMAGE_TAG" | sed 's|[:/]|-|g')
          TEST_CREDS_TAG_HASH=$(echo "$TEST_CREDS_IMAGE_TAG" | sed 's|[:/]|-|g')

          # Generate hash of E2E test files and configurations
          WEB_FILES_HASH=$(find web-test-client .github/workflows/web-e2e-tests.yml -type f -exec sha256sum {} \; 2>/dev/null | sha256sum | cut -d' ' -f1 || echo "no-files")
          ANDROID_FILES_HASH=$(find android-test-client .github/workflows/android-e2e-tests.yml -type f -exec sha256sum {} \; 2>/dev/null | sha256sum | cut -d' ' -f1 || echo "no-files")

          # Generate branch/event context for cache key isolation
          if [[ "${{ github.event_name }}" == "pull_request" ]]; then
            CONTEXT_SUFFIX="pr-${{ github.event.pull_request.number }}"
          elif [[ "${{ github.ref_name }}" == "main" ]]; then
            CONTEXT_SUFFIX="main"
          else
            CONTEXT_SUFFIX="branch-${{ github.ref_name }}"
          fi

          # Create platform-specific cache keys with branch/event context
          WEB_CACHE_KEY="web-e2e-results-${WEBAUTHN_TAG_HASH}-${TEST_CREDS_TAG_HASH}-${WEB_FILES_HASH}-${CONTEXT_SUFFIX}"
          ANDROID_CACHE_KEY="android-e2e-results-${WEBAUTHN_TAG_HASH}-${TEST_CREDS_TAG_HASH}-${ANDROID_FILES_HASH}-${CONTEXT_SUFFIX}"

          echo "web-key=${WEB_CACHE_KEY}" >> $GITHUB_OUTPUT
          echo "android-key=${ANDROID_CACHE_KEY}" >> $GITHUB_OUTPUT

          echo "ðŸ”‘ Cache Keys Generated:"
          echo "  Web E2E: ${WEB_CACHE_KEY}"
          echo "  Android E2E: ${ANDROID_CACHE_KEY}"
          echo "ðŸ·ï¸  Image Tags:"
          echo "  WebAuthn: ${WEBAUTHN_IMAGE_TAG} â†’ ${WEBAUTHN_TAG_HASH}"
          echo "ðŸŽ¯ Context: ${CONTEXT_SUFFIX}"
          echo "  Test Creds: ${TEST_CREDS_IMAGE_TAG} â†’ ${TEST_CREDS_TAG_HASH}"

      - name: Check Web E2E cache
        id: web-cache
        uses: actions/cache@v4
        with:
          key: ${{ steps.cache-keys.outputs.web-key }}
          path: |
            web-e2e-cache/
            web-e2e-results.json
          lookup-only: true

      - name: Check Android E2E cache
        id: android-cache
        uses: actions/cache@v4
        with:
          key: ${{ steps.cache-keys.outputs.android-key }}
          path: |
            android-e2e-cache/
            android-e2e-results.json
          lookup-only: true

      - name: Intelligent E2E test scope determination with component awareness
        id: determine-scope
        run: |
          echo "ðŸ” Analyzing component changes for intelligent E2E test orchestration..."
          echo "ðŸ“‹ Component Changes:"
          echo "  WebAuthn Server: ${{ inputs.webauthn-server-changed }}"
          echo "  Test Credentials Service: ${{ inputs.test-credentials-service-changed }}"
          echo "  OpenAPI Specification: ${{ inputs.openapi-changed }}"
          echo "  E2E Tests: ${{ inputs.e2e-tests-changed }}"
          echo ""
          
          # Initialize variables
          SHOULD_RUN_WEB="false"
          SHOULD_RUN_ANDROID="false"
          SKIP_WEB="true"
          SKIP_ANDROID="true"
          # Component-specific E2E test triggering logic
          SERVER_CHANGED="${{ inputs.webauthn-server-changed }}"
          CREDS_CHANGED="${{ inputs.test-credentials-service-changed }}"
          API_CHANGED="${{ inputs.openapi-changed }}"
          E2E_CHANGED="${{ inputs.e2e-tests-changed }}"
          
          # Determine which tests to run based on component changes
          if [[ "$SERVER_CHANGED" == "true" || "$CREDS_CHANGED" == "true" ]]; then
            # Server components changed: Full E2E test suite required
            SHOULD_RUN_WEB="true"
            SHOULD_RUN_ANDROID="true"
            echo "ðŸ”§ Server components changed - requiring full E2E test suite"
          elif [[ "$API_CHANGED" == "true" ]]; then
            # OpenAPI changed: Focus on client integration tests
            SHOULD_RUN_WEB="true"
            SHOULD_RUN_ANDROID="true"
            echo "ðŸ”„ OpenAPI changed - focusing on client integration validation"
          elif [[ "$E2E_CHANGED" == "true" ]]; then
            # Only E2E tests changed: Run specific test suites that changed
            # Check which E2E test files changed to determine scope
            if find web-test-client -name "*.spec.ts" -o -name "*.test.ts" -newer .git/FETCH_HEAD 2>/dev/null | grep -q .; then
              SHOULD_RUN_WEB="true"
              echo "ðŸ“± Web E2E test files changed - including web tests"
            fi
            if find android-test-client -name "*.kt" -newer .git/FETCH_HEAD 2>/dev/null | grep -q .; then
              SHOULD_RUN_ANDROID="true"
              echo "ðŸ¤– Android E2E test files changed - including Android tests"
            fi
          else
            echo "â„¹ï¸ No components requiring E2E tests changed"
          fi
          
          # Apply cache optimization (skip if cache hit and no forced execution)
          if [[ "$SHOULD_RUN_WEB" == "true" ]]; then
            if [[ "${{ steps.web-cache.outputs.cache-hit }}" != "true" ]]; then
              SKIP_WEB="false"
            else
              echo "ðŸ’¾ Web E2E cache hit - can skip execution"
            fi
          fi
          
          if [[ "$SHOULD_RUN_ANDROID" == "true" ]]; then
            if [[ "${{ steps.android-cache.outputs.cache-hit }}" != "true" ]]; then
              SKIP_ANDROID="false"
            else
              echo "ðŸ’¾ Android E2E cache hit - can skip execution"
            fi
          fi
          
          # Set outputs
          echo "should-run-web-e2e=$SHOULD_RUN_WEB" >> $GITHUB_OUTPUT
          echo "should-run-android-e2e=$SHOULD_RUN_ANDROID" >> $GITHUB_OUTPUT
          echo "skip-web-e2e=$SKIP_WEB" >> $GITHUB_OUTPUT
          echo "skip-android-e2e=$SKIP_ANDROID" >> $GITHUB_OUTPUT
          
          echo ""
          echo "ðŸŽ¯ E2E Test Execution Plan:"
          echo "  Web E2E: $SHOULD_RUN_WEB (will skip: $SKIP_WEB, cache hit: ${{ steps.web-cache.outputs.cache-hit }})"
          echo "  Android E2E: $SHOULD_RUN_ANDROID (will skip: $SKIP_ANDROID, cache hit: ${{ steps.android-cache.outputs.cache-hit }})"
      
      - name: Component-aware execution and cache summary
        run: |
          echo "ðŸ“Š E2E Test Strategy Summary:"
          echo "ðŸ“‹ Component Analysis:"
          echo "  Component triggers: Server=${{ inputs.webauthn-server-changed }}, Creds=${{ inputs.test-credentials-service-changed }}, API=${{ inputs.openapi-changed }}, E2E=${{ inputs.e2e-tests-changed }}"
          echo ""
          echo "ðŸ’¾ Cache Optimization:"
          echo "  Web E2E cache hit: ${{ steps.web-cache.outputs.cache-hit }}"
          echo "  Android E2E cache hit: ${{ steps.android-cache.outputs.cache-hit }}"
          echo ""
          echo "ðŸƒ Final Execution Plan:"
          echo "  Web E2E: ${{ steps.determine-scope.outputs.skip-web-e2e == 'false' && 'RUN' || 'SKIP' }} (needed: ${{ steps.determine-scope.outputs.should-run-web-e2e }})"
          echo "  Android E2E: ${{ steps.determine-scope.outputs.skip-android-e2e == 'false' && 'RUN' || 'SKIP' }} (needed: ${{ steps.determine-scope.outputs.should-run-android-e2e }})"
          echo "  Parallel Execution: ${{ (steps.determine-scope.outputs.skip-web-e2e == 'false' && steps.determine-scope.outputs.skip-android-e2e == 'false') && 'YES' || 'NO' }}"

  # Job 3: Validate Docker images are available with enhanced coordination
  validate-images:
    runs-on: ubuntu-latest
    needs: [ setup-config, analyze-e2e-requirements ]
    outputs:
      webauthn-server-ready: ${{ steps.check-webauthn.outputs.available }}
      test-credentials-ready: ${{ steps.check-test-credentials.outputs.available }}
    steps:
      - name: Log in to the Container registry
        uses: docker/login-action@v3
        with:
          registry: ${{ needs.setup-config.outputs.docker-registry }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Check WebAuthn Server image availability
        id: check-webauthn
        run: |
          echo "ðŸ” Checking WebAuthn Server image: ${{ env.WEBAUTHN_SERVER_IMAGE }}"
          if docker manifest inspect "${{ env.WEBAUTHN_SERVER_IMAGE }}" > /dev/null 2>&1; then
            echo "âœ… WebAuthn Server image is available"
            echo "available=true" >> $GITHUB_OUTPUT
          else
            echo "âŒ WebAuthn Server image not found"
            echo "available=false" >> $GITHUB_OUTPUT
          fi

      - name: Check Test Credentials Service image availability
        id: check-test-credentials
        run: |
          echo "ðŸ” Checking Test Credentials Service image: ${{ env.TEST_CREDENTIALS_IMAGE }}"
          if docker manifest inspect "${{ env.TEST_CREDENTIALS_IMAGE }}" > /dev/null 2>&1; then
            echo "âœ… Test Credentials Service image is available"
            echo "available=true" >> $GITHUB_OUTPUT
          else
            echo "âŒ Test Credentials Service image not found"
            echo "available=false" >> $GITHUB_OUTPUT
          fi

  # Job 4: Generate version for client library coordination
  generate-version:
    name: Generate version
    runs-on: ubuntu-latest
    outputs:
      version: ${{ steps.generate-version.outputs.version }}
      is-prerelease: ${{ steps.generate-version.outputs.is-prerelease }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0  # Fetch all history and tags for version continuity

      - name: Generate library version
        id: generate-version
        env:
          BASE_VERSION: ${{ env.BASE_VERSION }}
          GITHUB_EVENT_NAME: ${{ github.event_name }}
          GITHUB_REF_NAME: ${{ github.ref_name }}
          GITHUB_RUN_NUMBER: ${{ github.run_number }}
          GITHUB_PR_NUMBER: ${{ github.event.pull_request.number || '' }}
        run: |
          echo "ðŸŽ¯ Generating client version with centralized version manager"
          ./scripts/core/version-manager.sh generate

  # Job 5: Publish client libraries with component-aware coordination
  # VERSION PATTERN: pr-{PR_NUMBER}.{RUN_NUMBER} for staging packages
  # REGISTRY: GitHub Packages (staging registry for E2E testing)
  # SCOPE: @vmenon25/*-staging packages for isolated testing
  publish-client-libraries:
    uses: ./.github/workflows/client-publish.yml
    needs: [ setup-config, validate-images, generate-version, analyze-e2e-requirements ]
    if: needs.validate-images.outputs.webauthn-server-ready == 'true' && needs.validate-images.outputs.test-credentials-ready == 'true'
    permissions:
      contents: write  # Required for creating GitHub releases (production only)
      packages: write  # Required for publishing to GitHub Packages
      id-token: write  # Required for npm publishing
    with:
      publish-type: "staging"
      client-version: ${{ needs.generate-version.outputs.version }}
      workflow-identifier: ${{ github.event.pull_request.number || github.run_number || 'main' }}
    secrets:
      GRADLE_ENCRYPTION_KEY: ${{ secrets.GRADLE_ENCRYPTION_KEY }}

  # Job 6: Enhanced Web E2E tests with parallel execution optimization
  call-web-e2e-tests:
    uses: ./.github/workflows/web-e2e-tests.yml
    needs: [ setup-config, validate-images, generate-version, publish-client-libraries, analyze-e2e-requirements ]
    if: |
      needs.validate-images.outputs.webauthn-server-ready == 'true' &&
      needs.validate-images.outputs.test-credentials-ready == 'true' &&
      needs.publish-client-libraries.result == 'success' &&
      needs.analyze-e2e-requirements.outputs.should-run-web-e2e == 'true' &&
      needs.analyze-e2e-requirements.outputs.skip-web-e2e == 'false'
    secrets: inherit
    with:
      webauthn-server-image: ${{ inputs.webauthn_server_image }}
      test-credentials-image: ${{ inputs.test_credentials_image }}
      workflow-identifier: ${{ github.event.pull_request.number || github.run_number || 'main' }}
      java-version: ${{ needs.setup-config.outputs.java-version }}
      typescript-package-name: ${{ needs.publish-client-libraries.outputs.typescript-package-name }}
      client-version: ${{ needs.generate-version.outputs.version }}
      cache-key: ${{ needs.analyze-e2e-requirements.outputs.cache-key-web }}

  # Job 7: Enhanced Android E2E tests with parallel execution optimization
  call-android-e2e-tests:
    uses: ./.github/workflows/android-e2e-tests.yml
    needs: [ setup-config, validate-images, generate-version, publish-client-libraries, analyze-e2e-requirements ]
    if: |
      needs.validate-images.outputs.webauthn-server-ready == 'true' &&
      needs.validate-images.outputs.test-credentials-ready == 'true' &&
      needs.publish-client-libraries.result == 'success' &&
      needs.analyze-e2e-requirements.outputs.should-run-android-e2e == 'true' &&
      needs.analyze-e2e-requirements.outputs.skip-android-e2e == 'false'
    secrets: inherit
    with:
      webauthn-server-image: ${{ inputs.webauthn_server_image }}
      test-credentials-image: ${{ inputs.test_credentials_image }}
      workflow-identifier: ${{ github.event.pull_request.number || github.run_number || 'main' }}
      java-version: ${{ needs.setup-config.outputs.java-version }}
      android-api-version: ${{ needs.setup-config.outputs.android-api-version }}
      android-package-name: ${{ needs.publish-client-libraries.outputs.android-package-name }}
      client-version: ${{ needs.generate-version.outputs.version }}
      cache-key: ${{ needs.analyze-e2e-requirements.outputs.cache-key-android }}

  # Job 8: Handle cached Web E2E results with enhanced component awareness
  web-e2e-cached:
    runs-on: ubuntu-latest
    needs: [ analyze-e2e-requirements ]
    if: |
      needs.analyze-e2e-requirements.outputs.should-run-web-e2e == 'true' &&
      needs.analyze-e2e-requirements.outputs.skip-web-e2e == 'true'
    outputs:
      tests-passed: "true"
      artifact-name: "web-e2e-cached-results"
    steps:
      - name: Restore cached Web E2E results
        uses: actions/cache@v4
        with:
          key: ${{ needs.analyze-e2e-requirements.outputs.cache-key-web }}
          path: |
            web-e2e-cache/
            web-e2e-results.json
          fail-on-cache-miss: true

      - name: Report cached results
        run: |
          echo "âœ… Web E2E tests skipped - using cached results"
          echo "Cache key: ${{ needs.analyze-e2e-requirements.outputs.cache-key-web }}"
          echo "Previous test run was successful for identical conditions"
          if [ -f web-e2e-results.json ]; then
            echo "ðŸ“Š Cached test results available"
            cat web-e2e-results.json || echo "{\"status\": \"cached\", \"tests_passed\": true}"
          fi

  # Job 9: Handle cached Android E2E results with enhanced component awareness
  android-e2e-cached:
    runs-on: ubuntu-latest
    needs: [ analyze-e2e-requirements ]
    if: |
      needs.analyze-e2e-requirements.outputs.should-run-android-e2e == 'true' &&
      needs.analyze-e2e-requirements.outputs.skip-android-e2e == 'true'
    outputs:
      tests-passed: "true"
      artifact-name: "android-e2e-cached-results"
    steps:
      - name: Restore cached Android E2E results
        uses: actions/cache@v4
        with:
          key: ${{ needs.analyze-e2e-requirements.outputs.cache-key-android }}
          path: |
            android-e2e-cache/
            android-e2e-results.json
          fail-on-cache-miss: true

      - name: Report cached results
        run: |
          echo "âœ… Android E2E tests skipped - using cached results"
          echo "Cache key: ${{ needs.analyze-e2e-requirements.outputs.cache-key-android }}"
          echo "Previous test run was successful for identical conditions"
          if [ -f android-e2e-results.json ]; then
            echo "ðŸ“Š Cached test results available"
            cat android-e2e-results.json || echo "{\"status\": \"cached\", \"tests_passed\": true}"
          fi

  # Job 10: Cross-platform coordination analysis
  analyze-cross-platform-results:
    runs-on: ubuntu-latest
    needs: [ analyze-e2e-requirements, call-web-e2e-tests, call-android-e2e-tests, web-e2e-cached, android-e2e-cached ]
    if: always()
    outputs:
      overall-success: ${{ steps.analyze.outputs.overall-success }}
      parallel-execution: ${{ steps.analyze.outputs.parallel-execution }}
      performance-summary: ${{ steps.analyze.outputs.performance-summary }}
    steps:
      - name: Analyze cross-platform E2E test coordination
        id: analyze
        run: |
          echo "ðŸ“Š Analyzing cross-platform E2E test coordination results..."
          echo "ðŸ“‹ Execution Analysis:"
          echo ""
          
          # Determine if tests ran in parallel
          WEB_EXECUTED="false"
          ANDROID_EXECUTED="false"
          PARALLEL_EXECUTION="false"
          
          if [[ "${{ needs.call-web-e2e-tests.result }}" == "success" ]] || [[ "${{ needs.web-e2e-cached.result }}" == "success" ]]; then
            WEB_EXECUTED="true"
          fi
          
          if [[ "${{ needs.call-android-e2e-tests.result }}" == "success" ]] || [[ "${{ needs.android-e2e-cached.result }}" == "success" ]]; then
            ANDROID_EXECUTED="true"
          fi
          
          if [[ "$WEB_EXECUTED" == "true" && "$ANDROID_EXECUTED" == "true" ]]; then
            PARALLEL_EXECUTION="true"
            echo "âš™ï¸ Parallel cross-platform execution achieved"
          elif [[ "$WEB_EXECUTED" == "true" || "$ANDROID_EXECUTED" == "true" ]]; then
            echo "ðŸŽ¯ Single platform execution (optimized)"
          else
            echo "âš ï¸ No E2E tests executed"
          fi
          
          # Overall success determination
          OVERALL_SUCCESS="true"
          if [[ "${{ needs.call-web-e2e-tests.result }}" == "failure" ]] || [[ "${{ needs.call-android-e2e-tests.result }}" == "failure" ]]; then
            OVERALL_SUCCESS="false"
          fi
          
          # Performance summary
          PERFORMANCE_SUMMARY="{"
          PERFORMANCE_SUMMARY="$PERFORMANCE_SUMMARY\"web_executed\": $WEB_EXECUTED,"
          PERFORMANCE_SUMMARY="$PERFORMANCE_SUMMARY\"android_executed\": $ANDROID_EXECUTED,"
          PERFORMANCE_SUMMARY="$PERFORMANCE_SUMMARY\"parallel_execution\": $PARALLEL_EXECUTION"
          PERFORMANCE_SUMMARY="$PERFORMANCE_SUMMARY}"
          
          echo "overall-success=$OVERALL_SUCCESS" >> $GITHUB_OUTPUT
          echo "parallel-execution=$PARALLEL_EXECUTION" >> $GITHUB_OUTPUT
          echo "performance-summary=$PERFORMANCE_SUMMARY" >> $GITHUB_OUTPUT
          
          echo ""
          echo "âœ… Cross-Platform Coordination Analysis:"
          echo "  Overall Success: $OVERALL_SUCCESS"
          echo "  Parallel Execution: $PARALLEL_EXECUTION"
          echo "  Web Platform: $WEB_EXECUTED"
          echo "  Android Platform: $ANDROID_EXECUTED"

  # Job 11: Enhanced E2E test results reporting with component analysis
  report-results:
    runs-on: ubuntu-latest
    needs: [ validate-images, analyze-cross-platform-results, call-web-e2e-tests, call-android-e2e-tests, web-e2e-cached, android-e2e-cached ]
    if: always() && github.event_name == 'pull_request'
    permissions:
      contents: read
      pull-requests: write
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Enhanced PR comment with component-aware E2E results
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          GITHUB_REPOSITORY_OWNER: ${{ github.repository_owner }}
          GITHUB_REPOSITORY_NAME: ${{ github.event.repository.name }}
          PR_NUMBER: ${{ github.event.pull_request.number }}
          VALIDATION_RESULT: ${{ needs.validate-images.result }}
          WEB_E2E_RESULT: ${{ needs.call-web-e2e-tests.result }}
          ANDROID_E2E_RESULT: ${{ needs.call-android-e2e-tests.result }}
          WEB_TESTS_PASSED: ${{ needs.call-web-e2e-tests.outputs.tests-passed }}
          ANDROID_TESTS_PASSED: ${{ needs.call-android-e2e-tests.outputs.tests-passed }}
          WEB_ARTIFACT_NAME: ${{ needs.call-web-e2e-tests.outputs.artifact-name }}
          ANDROID_ARTIFACT_NAME: ${{ needs.call-android-e2e-tests.outputs.artifact-name }}
          WEBAUTHN_SERVER_IMAGE: ${{ env.WEBAUTHN_SERVER_IMAGE }}
          TEST_CREDENTIALS_IMAGE: ${{ env.TEST_CREDENTIALS_IMAGE }}
          # Enhanced component analysis data
          OVERALL_SUCCESS: ${{ needs.analyze-cross-platform-results.outputs.overall-success }}
          PARALLEL_EXECUTION: ${{ needs.analyze-cross-platform-results.outputs.parallel-execution }}
          PERFORMANCE_SUMMARY: ${{ needs.analyze-cross-platform-results.outputs.performance-summary }}
        run: |
          echo "ðŸ“¢ Creating enhanced E2E results comment with component analysis..."
          echo "ðŸ“‹ Enhanced Results Data:"
          echo "  Overall Success: $OVERALL_SUCCESS"
          echo "  Parallel Execution: $PARALLEL_EXECUTION"
          echo "  Performance Summary: $PERFORMANCE_SUMMARY"
          
          chmod +x scripts/ci/create-e2e-results-comment.cjs
          node scripts/ci/create-e2e-results-comment.cjs
