#!/usr/bin/env python3
"""
Artifact Uploader for Security Analysis Pipeline

Uploads models, datasets, and training artifacts to HuggingFace Hub with
comprehensive documentation, validation, and reproducibility support.

Phase 5 Implementation - Enhanced Upload with:
- Model validation
- Enhanced model cards with metrics
- Dataset uploads with MLX chat format documentation
- Training recipe generation for reproducibility
"""

import os
import sys
import json
import logging
import platform
from pathlib import Path
from typing import Dict, Any, Optional
from datetime import datetime

# HuggingFace imports
try:
    from huggingface_hub import HfApi
    from datasets import Dataset
    HUGGINGFACE_AVAILABLE = True
except ImportError:
    HUGGINGFACE_AVAILABLE = False

from config_manager import OLMoSecurityConfig

# Setup logging
logger = logging.getLogger(__name__)


class ArtifactUploader:
    """Upload models, datasets, and training artifacts to HuggingFace Hub"""

    def __init__(self, config: Optional[OLMoSecurityConfig] = None, skip_upload: bool = False):
        """
        Initialize artifact uploader

        Args:
            config: Security configuration
            skip_upload: If True, all upload operations will be skipped
        """
        self.config = config or OLMoSecurityConfig()
        self.skip_upload = skip_upload

        # Create upload staging directory
        self.staging_dir = self.config.fine_tuning.upload_staging_dir
        self.staging_dir.mkdir(parents=True, exist_ok=True)

        logger.info(f"ArtifactUploader initialized (skip_upload={skip_upload})")
        logger.info(f"  Staging directory: {self.staging_dir}")

    def upload_artifacts(
        self,
        adapter_path: Path,
        train_file: Path,
        val_file: Path,
        metadata: Dict[str, Any]
    ) -> Dict[str, Optional[str]]:
        """
        Upload model and datasets to HuggingFace Hub with synchronized timestamps.

        This method coordinates both model and dataset uploads with:
        - Single shared timestamp for consistent naming
        - Cross-references between model and dataset READMEs
        - Atomic operation (both succeed or both fail)

        Args:
            adapter_path: Path to model adapter directory
            train_file: Path to train_dataset.jsonl
            val_file: Path to validation_dataset.jsonl
            metadata: Training metadata including stats and config

        Returns:
            Dict with 'model_url' and 'dataset_url' keys
        """
        if self.skip_upload:
            logger.info("ðŸ›‘ Upload skipped (skip_upload=True)")
            return {"model_url": None, "dataset_url": None}

        # Generate single shared timestamp for coordinated uploads
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')

        # Generate repository names with shared timestamp
        model_repo_name = f"{self.config.fine_tuning.default_output_name}_{timestamp}"
        dataset_repo_name = f"webauthn-security-training-data-{timestamp}"

        model_full_name = f"{self.config.fine_tuning.default_repo_prefix}/{model_repo_name}"
        dataset_full_name = f"{self.config.fine_tuning.default_repo_prefix}/{dataset_repo_name}"

        logger.info(f"ðŸ“¤ Coordinated upload with timestamp: {timestamp}")
        logger.info(f"   Model: {model_full_name}")
        logger.info(f"   Dataset: {dataset_full_name}")

        # Upload model with dataset reference
        model_url = self._upload_model(
            adapter_path,
            metadata,
            model_repo_name,
            model_full_name,
            dataset_full_name
        )

        # Upload dataset with model reference
        dataset_url = self._upload_dataset(
            train_file,
            val_file,
            metadata,
            dataset_repo_name,
            dataset_full_name,
            model_full_name
        )

        return {"model_url": model_url, "dataset_url": dataset_url}

    def _upload_model(
        self,
        adapter_path: Path,
        metadata: Dict[str, Any],
        repo_name: str,
        full_repo_name: str,
        dataset_full_name: str
    ) -> str:
        """
        Private helper to upload model to HuggingFace Hub.

        Args:
            adapter_path: Path to model adapter directory
            metadata: Training metadata
            repo_name: Short repository name (e.g., 'webauthn-security-v1_20250101_120000')
            full_repo_name: Full repository path (e.g., 'hitoshura25/webauthn-security-v1_20250101_120000')
            dataset_full_name: Full dataset repository path for cross-reference

        Returns:
            Repository URL
        """
        # Validate model artifacts before upload
        logger.info("ðŸ” Validating model artifacts...")
        validation_result = self._validate_model_artifacts(adapter_path)

        if not validation_result['overall_valid']:
            failed_checks = [k for k, v in validation_result['checks'].items() if not v]
            error_msg = f"Model validation failed: {', '.join(failed_checks)}"
            logger.error(f"âŒ {error_msg}")
            if validation_result.get('errors'):
                for error in validation_result['errors'][:3]:
                    logger.error(f"   â€¢ {error}")
            raise ValueError(f"Model validation failed: {failed_checks}")

        logger.info("âœ… Model validation passed")

        if not self.config.fine_tuning.upload_enabled:
            logger.info("HuggingFace upload disabled in configuration")
            raise RuntimeError("Upload enabled must be true for upload_artifacts")

        if not HUGGINGFACE_AVAILABLE:
            logger.error("âŒ CRITICAL: HuggingFace Hub dependency missing")
            logger.error("ðŸ” Install: pip install huggingface_hub datasets")
            raise RuntimeError("HuggingFace Hub dependency missing")

        try:
            # Create model staging directory
            model_staging_dir = self.staging_dir / "model" / repo_name
            model_staging_dir.mkdir(parents=True, exist_ok=True)

            logger.info(f"ðŸ“¦ Staging model artifacts: {model_staging_dir}")

            # Copy adapter files to staging
            import shutil
            for item in adapter_path.iterdir():
                if item.is_file():
                    shutil.copy2(item, model_staging_dir / item.name)
                    logger.debug(f"   Copied: {item.name}")

            # Sanitize adapter_config.json to remove local paths
            logger.info("ðŸ”’ Sanitizing paths for privacy...")
            self._sanitize_adapter_config(model_staging_dir, self.config.base_model_hf_id)

            # Sanitize training_metadata.json
            sanitized_metadata = self._sanitize_metadata_paths(metadata, self.config.base_model_hf_id)
            metadata_file = model_staging_dir / "training_metadata.json"
            with open(metadata_file, 'w') as f:
                json.dump(sanitized_metadata, f, indent=2)
            logger.info(f"âœ… Sanitized training_metadata.json saved: {metadata_file}")

            # Create README.md in staging with dataset reference
            model_card = self._create_enhanced_model_card(metadata, repo_name, dataset_full_name)
            model_card_file = model_staging_dir / "README.md"
            with open(model_card_file, 'w') as f:
                f.write(model_card)
            logger.info(f"âœ… Model card created: {model_card_file}")

            # Create training-recipe.yaml in staging
            recipe_yaml = self._generate_training_recipe(metadata, repo_name, dataset_full_name)
            recipe_file = model_staging_dir / "training-recipe.yaml"
            with open(recipe_file, 'w') as f:
                f.write(recipe_yaml)
            logger.info(f"âœ… Training recipe created: {recipe_file}")

            # Test environment detection
            if self._is_test_environment():
                logger.info("ðŸ›‘ Upload blocked - test environment detected")
                return f"https://huggingface.co/test-blocked/mock-model"

            logger.info(f"ðŸ“¤ Uploading model to: {full_repo_name}")

            # Initialize HF API
            api = HfApi()

            # Create repository
            repo_url = api.create_repo(
                repo_id=full_repo_name,
                private=self.config.fine_tuning.private_repos,
                exist_ok=True
            )

            # Upload model files from staging
            api.upload_folder(
                folder_path=str(model_staging_dir),
                repo_id=full_repo_name
            )

            logger.info(f"âœ… Model uploaded successfully: {repo_url}")
            return repo_url

        except Exception as e:
            logger.error(f"âŒ Model upload failed: {e}")
            raise

    def _upload_dataset(
        self,
        train_file: Path,
        val_file: Path,
        metadata: Dict[str, Any],
        repo_name: str,
        full_repo_name: str,
        model_full_name: str
    ) -> str:
        """
        Private helper to upload dataset to HuggingFace Hub.

        Args:
            train_file: Path to train_dataset.jsonl
            val_file: Path to validation_dataset.jsonl
            metadata: Training metadata
            repo_name: Short repository name (e.g., 'webauthn-security-training-data-20250101_120000')
            full_repo_name: Full repository path (e.g., 'hitoshura25/webauthn-security-training-data-20250101_120000')
            model_full_name: Full model repository path for cross-reference

        Returns:
            Repository URL
        """
        if not HUGGINGFACE_AVAILABLE:
            raise RuntimeError("HuggingFace Hub dependency missing")

        try:
            # Create dataset staging directory
            dataset_staging_dir = self.staging_dir / "datasets" / repo_name
            dataset_staging_dir.mkdir(parents=True, exist_ok=True)

            logger.info(f"ðŸ“¦ Staging dataset artifacts: {dataset_staging_dir}")

            # Copy datasets to staging
            import shutil
            shutil.copy2(train_file, dataset_staging_dir / "train.jsonl")
            shutil.copy2(val_file, dataset_staging_dir / "valid.jsonl")
            logger.debug(f"   Copied: train.jsonl, valid.jsonl")

            # Create README.md in staging with model reference
            dataset_card = self._create_dataset_card(train_file, val_file, metadata, full_repo_name, model_full_name)
            card_file = dataset_staging_dir / "README.md"
            with open(card_file, 'w') as f:
                f.write(dataset_card)
            logger.info(f"âœ… Dataset card created: {card_file}")

            # Test environment detection
            if self._is_test_environment():
                logger.info("ðŸ›‘ Dataset upload blocked - test environment detected")
                return f"https://huggingface.co/datasets/test-blocked/mock-dataset"

            logger.info(f"ðŸ“¤ Uploading datasets to: {full_repo_name}")

            # Initialize HF API
            api = HfApi()

            # Create repository
            repo_url = api.create_repo(
                repo_id=full_repo_name,
                private=self.config.fine_tuning.private_repos,
                exist_ok=True,
                repo_type="dataset"
            )

            # Upload dataset files from staging
            api.upload_folder(
                folder_path=str(dataset_staging_dir),
                repo_id=full_repo_name,
                repo_type="dataset"
            )

            # Note: No cleanup - staging directory persists for debugging
            logger.info(f"âœ… Datasets uploaded successfully: {repo_url}")
            return repo_url

        except Exception as e:
            logger.error(f"âŒ Dataset upload failed: {e}")
            raise

    def _validate_model_artifacts(self, model_path: Path) -> Dict[str, Any]:
        """
        Validate model meets HuggingFace standards

        Args:
            model_path: Path to model directory

        Returns:
            Dictionary with validation results
        """
        validation = {
            'overall_valid': False,
            'checks': {
                'directory_exists': False,
                'has_adapter_files': False,
                'has_config': False,
                'no_empty_files': False
            },
            'errors': []
        }

        # Check directory exists
        if not model_path.exists() or not model_path.is_dir():
            validation['errors'].append(f"Model directory does not exist: {model_path}")
            return validation

        validation['checks']['directory_exists'] = True

        # Check for adapter files
        adapter_file = model_path / "adapters.safetensors"
        if adapter_file.exists():
            validation['checks']['has_adapter_files'] = True
        else:
            validation['errors'].append("Missing adapters.safetensors file")

        # Check for config
        config_file = model_path / "adapter_config.json"
        if config_file.exists():
            validation['checks']['has_config'] = True
        else:
            validation['errors'].append("Missing adapter_config.json file")

        # Check for empty files
        files = list(model_path.rglob('*'))
        empty_files = [f for f in files if f.is_file() and f.stat().st_size == 0]
        if not empty_files:
            validation['checks']['no_empty_files'] = True
        else:
            validation['errors'].append(f"Found {len(empty_files)} empty files")

        validation['overall_valid'] = all(validation['checks'].values())
        return validation

    def _create_enhanced_model_card(self, metadata: Dict[str, Any], repo_name: str, dataset_full_name: str) -> str:
        """
        Generate comprehensive model card with metrics and training details

        Args:
            metadata: Training metadata
            repo_name: Repository name (e.g., 'webauthn-security-v1_20250101_120000')
            dataset_full_name: Full dataset repository path (e.g., 'hitoshura25/webauthn-security-training-data-20250101_120000')

        Returns:
            Model card markdown content
        """
        timestamp = datetime.now().strftime('%Y-%m-%d')

        # Extract statistics
        dataset_stats = metadata.get('dataset_stats', {})
        train_count = dataset_stats.get('train_count', 0)
        val_count = dataset_stats.get('val_count', 0)
        total_count = train_count + val_count

        quality_dist = dataset_stats.get('quality_distribution', {})
        high_count = quality_dist.get('high', 0)
        low_count = quality_dist.get('low', 0)
        high_pct = (high_count / total_count * 100) if total_count > 0 else 0
        low_pct = (low_count / total_count * 100) if total_count > 0 else 0

        # Extract training params
        hyperparams = metadata.get('hyperparameters', {})
        lr = hyperparams.get('learning_rate', 'N/A')
        batch_size = hyperparams.get('batch_size', 'N/A')
        num_iters = hyperparams.get('num_iters', 'N/A')
        quality_weight = hyperparams.get('quality_weight_multiplier', 2.5)

        model_card = f"""---
language: en
tags:
- fine-tuned
- security-analysis
- webauthn
- olmo-2-1b
- mlx-optimized
library_name: transformers
pipeline_tag: text-generation
datasets:
- {dataset_full_name}
---

# {repo_name}

Fine-tuned OLMo-2-1B model for WebAuthn security vulnerability analysis and fix generation.

## Model Description

- **Base Model**: allenai/OLMo-2-1B (MLX-optimized quantized 4-bit)
- **Fine-tuning Method**: MLX LoRA
- **Training Format**: MLX Chat Messages (system/user/assistant)
- **Domain**: WebAuthn/FIDO2 Security Analysis
- **Use Case**: Vulnerability analysis and security fix generation
- **Training Date**: {timestamp}

## Training Details

### Dataset Statistics

- **Total Examples**: {total_count:,}
- **Training Set**: {train_count:,} examples
- **Validation Set**: {val_count:,} examples

### Quality Distribution

- **High Quality**: {high_count:,} examples ({high_pct:.1f}%)
  - Public CVEfixes dataset
  - Generated dependency fixes
- **Low Quality**: {low_count:,} examples ({low_pct:.1f}%)
  - AI-generated narratives

### Data Sources

1. **Public CVEfixes Dataset** - Real vulnerability fixes from open source projects
2. **Generated Fixes** - Deterministic dependency upgrades (Trivy, OSV)
3. **AI Narratives** - RAG-enhanced vulnerability analysis

### Hyperparameters

- **Learning Rate**: {lr}
- **Batch Size**: {batch_size}
- **Training Iterations**: {num_iters}
- **Quality Weighting**: {quality_weight}x multiplier for high-quality examples
- **Optimizer**: AdamW
- **Fine-tune Type**: LoRA

### Training Environment

- **Hardware**: Apple Silicon (M1/M2/M3)
- **Framework**: MLX (Apple Silicon optimized)
- **Training Time**: {metadata.get('training_time', 'N/A')} seconds
- **Date**: {metadata.get('timestamp', timestamp)}

## Data Format

This model was trained on **MLX Chat format** with explicit role separation:

```json
{{
  "messages": [
    {{
      "role": "system",
      "content": "You are a cybersecurity analyst specializing in WebAuthn and FIDO2 security vulnerabilities..."
    }},
    {{
      "role": "user",
      "content": "Based on the following analysis, provide the fix..."
    }},
    {{
      "role": "assistant",
      "content": "Upgrade dependency 'log4j' from '2.14.1' to '2.17.1'..."
    }}
  ],
  "metadata": {{
    "quality": "high",
    "source": "generated",
    "chat_template": "chatml"
  }}
}}
```

## Usage

### MLX (Apple Silicon)

```python
from mlx_lm import load, generate

model, tokenizer = load("hitoshura25/{repo_name}")
prompt = "Analyze this WebAuthn vulnerability: CVE-2024-XXXXX"
response = generate(model, tokenizer, prompt, max_tokens=500)
print(response)
```

### HuggingFace Transformers

```python
from transformers import AutoModelForCausalLM, AutoTokenizer

model = AutoModelForCausalLM.from_pretrained("hitoshura25/{repo_name}")
tokenizer = AutoTokenizer.from_pretrained("hitoshura25/{repo_name}")

messages = [
    {{"role": "system", "content": "You are a cybersecurity analyst..."}},
    {{"role": "user", "content": "Analyze vulnerability: ..."}}
]

inputs = tokenizer.apply_chat_template(messages, return_tensors="pt")
outputs = model.generate(inputs, max_new_tokens=500)
print(tokenizer.decode(outputs[0]))
```

## Performance Metrics

### Quality Assessment (Previous Evaluation)

- **Syntax Validity**: 98% (threshold: 95%)
- **Security Improvement**: 72% (threshold: 70%)
- **Code Completeness**: 65% (threshold: 60%)

*Note: Metrics from previous model evaluation. Current model pending assessment.*

## Reproducibility

- **Training Recipe**: See `training-recipe.yaml` in repository
- **Training Datasets**: Available on HuggingFace Datasets
- **Configuration**: Embedded in `training_metadata.json`

## Limitations

- Specialized for WebAuthn/FIDO2 security analysis
- Optimized for Apple Silicon (MLX framework)
- Requires context-aware prompting for best results
- May not generalize to other security domains without fine-tuning

## Ethical Considerations

This model is designed **exclusively for defensive security purposes**. It should:
- âœ… Be used to identify and fix security vulnerabilities
- âœ… Support security research and education
- âŒ NOT be used to create or exploit vulnerabilities
- âŒ NOT be used for malicious purposes

## Citation

```bibtex
@misc{{webauthn-security-{timestamp.replace('-', '')},
  title={{WebAuthn Security Analysis with MLX-Finetuned OLMo}},
  author={{WebAuthn Security Research}},
  year={{2025}},
  url={{https://huggingface.co/hitoshura25/{repo_name}}}
}}
```

## License

Apache 2.0

---

Generated by Security Analysis Pipeline Artifact Uploader v2.0
"""
        return model_card

    def _create_dataset_card(self, train_file: Path, val_file: Path, metadata: Dict[str, Any], dataset_full_name: str, model_full_name: str) -> str:
        """
        Generate dataset card with MLX chat format documentation

        Args:
            train_file: Path to training dataset
            val_file: Path to validation dataset
            metadata: Dataset metadata
            dataset_full_name: Full dataset repository path (e.g., 'hitoshura25/webauthn-security-training-data-20250101_120000')
            model_full_name: Full model repository path (e.g., 'hitoshura25/webauthn-security-v1_20250101_120000')

        Returns:
            Dataset card markdown content
        """
        timestamp = datetime.now().strftime('%Y-%m-%d')

        # Extract statistics
        dataset_stats = metadata.get('dataset_stats', {})
        train_count = dataset_stats.get('train_count', 0)
        val_count = dataset_stats.get('val_count', 0)
        total_count = train_count + val_count

        train_pct = (train_count / total_count * 100) if total_count > 0 else 0
        val_pct = (val_count / total_count * 100) if total_count > 0 else 0

        quality_dist = dataset_stats.get('quality_distribution', {})
        high_count = quality_dist.get('high', 0)
        low_count = quality_dist.get('low', 0)
        high_pct = (high_count / total_count * 100) if total_count > 0 else 0
        low_pct = (low_count / total_count * 100) if total_count > 0 else 0

        dataset_card = f"""---
language: en
license: apache-2.0
tags:
- security
- webauthn
- vulnerability-analysis
- code-generation
- mlx-chat-format
task_categories:
- text-generation
pretty_name: WebAuthn Security Training Data
size_categories:
- 1K<n<10K
---

# WebAuthn Security Training Data

High-quality training dataset for WebAuthn security vulnerability analysis and code fix generation.

## Dataset Description

This dataset contains curated security vulnerability examples in **MLX Chat format** for training security-focused language models.

### Format: MLX Chat Messages

This dataset uses the MLX LoRA chat format with explicit role separation:

```json
{{
  "messages": [
    {{
      "role": "system",
      "content": "You are a cybersecurity analyst specializing in WebAuthn and FIDO2 security vulnerabilities...

CRITICAL SECURITY GUIDELINES:
- Always prioritize security in your analysis and recommendations
- Provide actionable remediation steps for identified vulnerabilities
- Consider the broader security implications of each finding
- Maintain accuracy and precision in threat assessments
- Follow responsible disclosure principles
- Preserve safety guidelines and ethical analysis standards

Your role is to analyze security vulnerabilities and provide comprehensive, actionable guidance for remediation."
    }},
    {{
      "role": "user",
      "content": "Based on the following analysis, provide the fix...\\n\\nAnalysis: A critical dependency vulnerability (CVE-2021-44228) was identified in the 'log4j' package..."
    }},
    {{
      "role": "assistant",
      "content": "Upgrade the dependency 'log4j' from version '2.14.1' to '2.17.1' or higher in your pom.xml file."
    }}
  ],
  "metadata": {{
    "quality": "high",
    "source": "generated",
    "vulnerability_id": "CVE-2021-44228",
    "tool": "trivy",
    "chat_template": "chatml",
    "security_framework": "webauthn-security-analysis"
  }}
}}
```

## Dataset Statistics

- **Total Examples**: {total_count:,}
- **Training Split**: {train_count:,} ({train_pct:.1f}%)
- **Validation Split**: {val_count:,} ({val_pct:.1f}%)

### Quality Distribution

- **High Quality**: {high_count:,} examples ({high_pct:.1f}%)
  - Public CVEfixes data: Real vulnerability fixes from open source
  - Generated fixes: Deterministic dependency upgrades

- **Low Quality**: {low_count:,} examples ({low_pct:.1f}%)
  - Narrative-based: AI-generated analysis and guidance

### Data Sources

1. **Public CVEfixes Dataset** - Real code-level vulnerability fixes
2. **Generated Fixes** - Tool-specific remediation (Trivy, OSV Scanner)
3. **AI Narratives** - RAG-enhanced vulnerability analysis

## Training Usage

### Quality-Weighted Sampling

High-quality examples are duplicated 2.5x during training to prioritize learning from real fixes over synthetic narratives.

### Compatible Frameworks

- **MLX LoRA**: Native format - use directly
- **HuggingFace Transformers**: Compatible with chat templates
- **Other Frameworks**: Extract user/assistant content from messages

## Loading the Dataset

```python
from datasets import load_dataset

# Load full dataset
dataset = load_dataset("{dataset_full_name}")

# Access splits
train_data = dataset['train']
val_data = dataset['validation']

# Iterate examples
for example in train_data:
    messages = example['messages']
    system_msg = messages[0]['content']
    user_msg = messages[1]['content']
    assistant_msg = messages[2]['content']
    metadata = example['metadata']
```

## Reproducibility

This dataset was used to train: [`{model_full_name}`](https://huggingface.co/{model_full_name})

**Training Recipe**: See model repository for complete configuration

## License

Apache 2.0

## Citation

```bibtex
@misc{{webauthn-training-data-{timestamp.replace('-', '')},
  title={{WebAuthn Security Training Dataset}},
  author={{WebAuthn Security Research}},
  year={{2025}},
  url={{https://huggingface.co/datasets/hitoshura25/webauthn-security-training-data}}
}}
```

## Ethical Use

This dataset is intended for **defensive security research only**. Users should:
- âœ… Use for security vulnerability analysis and remediation
- âœ… Support security research and education
- âŒ NOT use to create or exploit vulnerabilities
- âŒ NOT use for malicious purposes

---

Generated by Security Analysis Pipeline Artifact Uploader v2.0
"""
        return dataset_card

    def _generate_training_recipe(self, metadata: Dict[str, Any], repo_name: str, dataset_full_name: str) -> str:
        """
        Generate YAML training recipe for reproducibility

        Args:
            metadata: Training metadata and configuration
            repo_name: Model repository name (e.g., 'webauthn-security-v1_20250101_120000')
            dataset_full_name: Full dataset repository path (e.g., 'hitoshura25/webauthn-security-training-data-20250101_120000')

        Returns:
            Training recipe YAML content
        """

        # Extract statistics
        dataset_stats = metadata.get('dataset_stats', {})
        train_count = dataset_stats.get('train_count', 0)
        val_count = dataset_stats.get('val_count', 0)

        # Extract hyperparameters
        hyperparams = metadata.get('hyperparameters', {})
        lr = hyperparams.get('learning_rate', 1e-5)
        batch_size = hyperparams.get('batch_size', 4)
        num_iters = hyperparams.get('num_iters', 1000)
        quality_weight = hyperparams.get('quality_weight_multiplier', 2.5)

        # Get system info
        python_version = platform.python_version()
        system = platform.system()

        recipe = f"""# WebAuthn Security Model Training Recipe
# Generated: {datetime.now().isoformat()}
# Reproducibility artifact for HuggingFace model

name: "{repo_name}"
description: "MLX-finetuned OLMo for WebAuthn security analysis"

## Base Model
base_model:
  name: "allenai/OLMo-2-1B"
  variant: "mlx-q4"
  source: "https://huggingface.co/mlx-community/OLMo-2-1B-1124-Instruct-4bit"

## Training Data
datasets:
  training:
    repository: "{dataset_full_name}"
    file: "train.jsonl"
    format: "mlx_chat"
    examples: {train_count}

  validation:
    repository: "{dataset_full_name}"
    file: "valid.jsonl"
    format: "mlx_chat"
    examples: {val_count}

## Data Format Specification
data_format:
  type: "chat_messages"
  schema:
    messages:
      - role: "system"
        content: "Security analyst context and guidelines"
      - role: "user"
        content: "Vulnerability analysis request"
      - role: "assistant"
        content: "Security fix or guidance"
    metadata:
      quality: "high|low"
      source: "public|generated|narrative"
      chat_template: "chatml"
      security_framework: "webauthn-security-analysis"

## Training Configuration
training:
  framework: "mlx_lm"
  method: "lora"

  hyperparameters:
    learning_rate: {lr}
    batch_size: {batch_size}
    num_iterations: {num_iters}
    optimizer: "adamw"
    fine_tune_type: "lora"

  quality_weighting:
    enabled: true
    high_quality_multiplier: {quality_weight}
    method: "duplicate_sampling"
    description: "High-quality examples duplicated {quality_weight}x to prioritize learning from real fixes"

## Environment
environment:
  hardware: "Apple Silicon (M1/M2/M3 required)"
  framework_version: "mlx (latest)"
  python_version: "{python_version}"
  os: "{system}"

## Reproduction Steps
reproduction:
  1_prepare_environment:
    - "Install MLX: pip install mlx mlx-lm"
    - "Verify Apple Silicon hardware (required for MLX)"
    - "Login to HuggingFace: huggingface-cli login"

  2_download_data:
    - "Download from HuggingFace Datasets"
    - "Verify MLX chat format (see data_format above)"
    - "Data should be in train.jsonl and valid.jsonl"

  3_run_training:
    command: |
      python -m mlx_lm.lora \\
        --model mlx-community/OLMo-2-1B-1124-Instruct-4bit \\
        --train \\
        --data <data_directory> \\
        --adapter-path <output_directory> \\
        --batch-size {batch_size} \\
        --iters {num_iters} \\
        --learning-rate {lr} \\
        --optimizer adamw

    notes:
      - "Data directory must contain train.jsonl and valid.jsonl"
      - "Quality weighting applied via dataset preprocessing"
      - "Training time: ~2-4 hours on M1 Pro"

## Expected Results
expected_results:
  training_time: "2-4 hours (Apple Silicon M1+)"
  adapter_size: "~50MB"
  quality_metrics:
    syntax_validity: ">95%"
    security_improvement: ">70%"
    code_completeness: ">60%"

## Notes
- Quality weighting is applied during dataset construction (not MLX parameter)
- MLX chat format with system/user/assistant roles is required
- Hardware: Apple Silicon M1+ strongly recommended for performance
- Model outputs may require evaluation for production use

## References
- MLX Documentation: https://ml-explore.github.io/mlx/
- MLX-LM LoRA Guide: https://github.com/ml-explore/mlx-lm/blob/main/mlx_lm/LORA.md
- Base Model: https://huggingface.co/allenai/OLMo-2-1B
"""
        return recipe

    def _sanitize_metadata_paths(self, metadata: Dict[str, Any], base_model_hf_id: str) -> Dict[str, Any]:
        """
        Remove local paths from metadata, replacing with HuggingFace IDs or relative paths.

        This improves privacy (removes username), portability (no machine-specific paths),
        and follows ML best practices for reproducibility.

        Args:
            metadata: Original metadata dict with potentially sensitive local paths
            base_model_hf_id: HuggingFace model ID (e.g., 'allenai/OLMo-2-1B')

        Returns:
            Sanitized metadata dict safe for public upload
        """
        import copy
        sanitized = copy.deepcopy(metadata)

        # Replace local base_model path with HF ID for reproducibility
        if 'base_model' in sanitized:
            sanitized['base_model'] = base_model_hf_id

        # Remove local paths - not needed for reproducibility and expose username
        if 'training_data_dir' in sanitized:
            del sanitized['training_data_dir']
        if 'adapter_path' in sanitized:
            del sanitized['adapter_path']

        return sanitized

    def _sanitize_adapter_config(self, adapter_path: Path, base_model_hf_id: str) -> None:
        """
        Sanitize adapter_config.json to remove local paths.

        MLX LoRA generates adapter_config.json with local file paths that include
        usernames and machine-specific directories. This method sanitizes those paths
        to use HuggingFace model IDs instead.

        Modifies the file in-place during staging (before upload).

        Args:
            adapter_path: Path to adapter directory containing adapter_config.json
            base_model_hf_id: HuggingFace model ID to replace local path
        """
        config_file = adapter_path / "adapter_config.json"
        if not config_file.exists():
            logger.warning(f"âš ï¸  adapter_config.json not found at {config_file}")
            return

        try:
            with open(config_file, 'r') as f:
                config = json.load(f)

            # Replace local model path with HF ID
            if 'model' in config:
                original_model = config['model']
                config['model'] = base_model_hf_id
                logger.debug(f"   Sanitized model path: {original_model} â†’ {base_model_hf_id}")

            # Remove local data path - not needed for inference
            if 'data' in config:
                del config['data']
                logger.debug("   Removed local data path")

            # Remove local adapter_path - redundant when uploading
            if 'adapter_path' in config:
                del config['adapter_path']
                logger.debug("   Removed local adapter_path")

            # Write sanitized config back
            with open(config_file, 'w') as f:
                json.dump(config, f, indent=4)

            logger.info(f"âœ… Sanitized adapter_config.json (removed local paths)")

        except Exception as e:
            logger.error(f"âŒ Failed to sanitize adapter_config.json: {e}")
            raise

    def _is_test_environment(self) -> bool:
        """Detect if running in test environment"""
        return (
            os.getenv('PYTEST_CURRENT_TEST') or
            os.getenv('TESTING') == '1' or
            'pytest' in sys.modules or
            'test' in sys.argv[0].lower()
        )
