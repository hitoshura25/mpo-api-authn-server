#!/usr/bin/env python3
"""
Advanced Data Augmentation for AI Security Enhancement

Implements 2024-2025 research-backed data augmentation techniques for small
security datasets to improve model performance and prevent overfitting.

Academic Foundation:
- MIT TACL Survey: Token-level augmentations for supervised learning
- IEEE 2024: Self-mixup achieves 1.84-4.66% accuracy improvements in few-shot scenarios
- Theodo Research: Support set augmentation improves accuracy from 48% to 81%

Classes:
- SecurityDataAugmentor: Main augmentation engine with self-mixup and support set enhancement
- AugmentationConfig: Configuration for augmentation parameters
- AugmentedExample: Enhanced training example with augmentation metadata

Usage:
    augmentor = SecurityDataAugmentor()
    augmented_data = augmentor.augment_training_data(original_examples)
"""

import logging
import random
import re
from dataclasses import dataclass, field
from typing import Dict, List, Optional, Any, Tuple
from enum import Enum

logger = logging.getLogger(__name__)


class AugmentationType(Enum):
    """Types of data augmentation techniques."""
    SELF_MIXUP = "self_mixup"
    SEMANTIC_VARIATION = "semantic_variation"
    SUPPORT_SET_ENHANCEMENT = "support_set_enhancement"
    CONTEXT_BLENDING = "context_blending"
    SEVERITY_PERSPECTIVE = "severity_perspective"


@dataclass
class AugmentationConfig:
    """Configuration for advanced data augmentation."""

    # Self-mixup parameters (IEEE 2024 research)
    mixup_alpha: float = 0.3                    # Optimal mixing ratio for security domain
    augmentation_factor: int = 4                # Target: 272â†’1088 samples (4x increase)

    # Support set enhancement parameters
    variation_count: int = 3                    # Number of variations per example
    semantic_diversity_threshold: float = 0.7   # Minimum semantic diversity

    # WebAuthn-specific patterns
    enable_domain_specific_augmentation: bool = True
    preserve_security_semantics: bool = True


@dataclass
class AugmentedExample:
    """Enhanced training example with augmentation metadata."""

    original_example: Dict[str, Any]
    augmented_content: Dict[str, Any]
    augmentation_type: AugmentationType
    augmentation_metadata: Dict[str, Any] = field(default_factory=dict)
    confidence_score: float = 1.0


class SecurityDataAugmentor:
    """
    Advanced data augmentation using 2024-2025 research techniques.

    Implements self-mixup and support set augmentation specifically optimized
    for security vulnerability datasets with small sample sizes.
    """

    def __init__(self, config: Optional[AugmentationConfig] = None):
        """Initialize the security data augmentor."""
        self.config = config or AugmentationConfig()
        self.logger = logging.getLogger(__name__)

        # WebAuthn-specific augmentation patterns
        self.vulnerability_templates = {
            'authentication': [
                'credential validation bypass',
                'session management flaw',
                'origin verification failure',
                'attestation validation error',
                'relying party configuration issue'
            ],
            'cryptographic': [
                'signature verification bypass',
                'key management vulnerability',
                'entropy weakness',
                'certificate validation error',
                'cryptographic protocol flaw'
            ],
            'configuration': [
                'CORS policy misconfiguration',
                'security header missing',
                'input validation bypass',
                'transport security issue',
                'API endpoint exposure'
            ],
            'implementation': [
                'race condition vulnerability',
                'memory safety issue',
                'error handling bypass',
                'state management flaw',
                'resource exhaustion'
            ]
        }

        # Semantic variation patterns for security context
        self.semantic_patterns = {
            'paraphrase': [
                ('vulnerability', 'security flaw'),
                ('exploit', 'attack vector'),
                ('mitigation', 'remediation'),
                ('validation', 'verification'),
                ('configuration', 'setup')
            ],
            'technical_detail': [
                ('high severity', 'critical impact potential'),
                ('input validation', 'user input sanitization'),
                ('authentication', 'identity verification'),
                ('authorization', 'access control'),
                ('encryption', 'cryptographic protection')
            ],
            'severity_perspective': [
                ('potential impact', 'security risk level'),
                ('attack vector', 'exploitation method'),
                ('remediation steps', 'security implementation'),
                ('vulnerable component', 'affected system'),
                ('security control', 'protective measure')
            ]
        }

    def augment_training_data(self, training_examples: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        Apply comprehensive data augmentation to training examples.

        Args:
            training_examples: Original training examples

        Returns:
            Augmented training examples with 4x increase target
        """
        self.logger.info(f"ðŸš€ Starting advanced data augmentation: {len(training_examples)} â†’ target {len(training_examples) * self.config.augmentation_factor}")

        augmented_examples = list(training_examples)  # Start with originals

        # Phase 1: Self-mixup augmentation (IEEE 2024 research)
        self.logger.info("ðŸ“Š Phase 1: Applying self-mixup augmentation...")
        mixup_examples = self.apply_self_mixup_augmentation(training_examples)
        augmented_examples.extend(mixup_examples)

        # Phase 2: Semantic variation enhancement
        self.logger.info("ðŸ”„ Phase 2: Generating semantic variations...")
        semantic_examples = self.apply_semantic_variations(training_examples)
        augmented_examples.extend(semantic_examples)

        # Phase 3: Context blending for diversity
        self.logger.info("ðŸŽ¯ Phase 3: Applying context blending...")
        blended_examples = self.apply_context_blending(training_examples)
        augmented_examples.extend(blended_examples)

        # Ensure quality and remove duplicates
        final_examples = self._ensure_quality_and_diversity(augmented_examples)

        augmentation_ratio = len(final_examples) / len(training_examples)
        self.logger.info(f"âœ… Advanced augmentation complete: {len(training_examples)} â†’ {len(final_examples)} ({augmentation_ratio:.1f}x)")

        return final_examples

    def apply_self_mixup_augmentation(self, training_examples: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        Apply self-mixup augmentation to increase dataset diversity.

        Research source: IEEE 2024 few-shot learning accuracy improvements of 1.84-4.66%
        Citation: https://ieeexplore.ieee.org/document/10547346

        Args:
            training_examples: Original training examples

        Returns:
            Self-mixup augmented examples
        """
        augmented_examples = []

        for original_example in training_examples:
            # Generate multiple mixup variants with different ratios
            for mix_ratio in [0.3, 0.5, 0.7]:
                try:
                    augmented = self._create_mixup_variant(original_example, mix_ratio)
                    if augmented:
                        augmented_examples.append(augmented)
                except Exception as e:
                    self.logger.warning(f"Failed to create mixup variant: {e}")
                    continue

        self.logger.info(f"  âœ… Self-mixup generated {len(augmented_examples)} variants")
        return augmented_examples

    def apply_semantic_variations(self, training_examples: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        Apply semantic variations to create diverse training examples.

        Args:
            training_examples: Original training examples

        Returns:
            Semantically varied examples
        """
        augmented_examples = []

        for original_example in training_examples:
            # Generate semantic variations
            for variation_type in ['paraphrase', 'technical_detail', 'severity_perspective']:
                try:
                    varied_example = self._apply_semantic_variation(original_example, variation_type)
                    if varied_example:
                        augmented_examples.append(varied_example)
                except Exception as e:
                    self.logger.warning(f"Failed to create semantic variation: {e}")
                    continue

        self.logger.info(f"  âœ… Semantic variations generated {len(augmented_examples)} examples")
        return augmented_examples

    def apply_context_blending(self, training_examples: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        Apply context blending to create diverse security contexts.

        Args:
            training_examples: Original training examples

        Returns:
            Context-blended examples
        """
        augmented_examples = []

        # Group examples by vulnerability type for intelligent blending
        grouped_examples = self._group_by_vulnerability_type(training_examples)

        for vuln_type, examples in grouped_examples.items():
            if len(examples) >= 2:  # Need at least 2 examples to blend
                blended = self._create_context_blended_variants(examples, vuln_type)
                augmented_examples.extend(blended)

        self.logger.info(f"  âœ… Context blending generated {len(augmented_examples)} examples")
        return augmented_examples

    def enhance_support_set(self, validation_examples: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        Support set augmentation - 2024 research shows 48%â†’81% accuracy improvement.

        Args:
            validation_examples: Original validation examples

        Returns:
            Enhanced validation examples
        """
        enhanced_examples = list(validation_examples)  # Start with originals

        for example in validation_examples:
            # Apply targeted support set enhancements
            variants = [
                self._apply_semantic_variation(example, 'paraphrase'),
                self._apply_semantic_variation(example, 'technical_detail'),
                self._apply_semantic_variation(example, 'severity_perspective')
            ]

            # Filter valid variants
            valid_variants = [v for v in variants if v is not None]
            enhanced_examples.extend(valid_variants)

        enhancement_ratio = len(enhanced_examples) / len(validation_examples)
        self.logger.info(f"âœ… Support set enhancement: {len(validation_examples)} â†’ {len(enhanced_examples)} ({enhancement_ratio:.1f}x)")

        return enhanced_examples

    def _create_mixup_variant(self, example: Dict[str, Any], mix_ratio: float) -> Optional[Dict[str, Any]]:
        """Create self-mixup variant by combining different aspects of same vulnerability."""

        # Extract the messages structure (assuming ChatML format)
        messages = example.get('messages', [])
        if not messages:
            return None

        # Find user and assistant messages
        user_msg = None
        assistant_msg = None

        for msg in messages:
            if msg.get('role') == 'user':
                user_msg = msg
            elif msg.get('role') == 'assistant':
                assistant_msg = msg

        if not user_msg or not assistant_msg:
            return None

        # Apply mixup to instruction (user message)
        mixed_instruction = self._blend_instruction_content(user_msg.get('content', ''), mix_ratio)

        # Apply mixup to response (assistant message)
        mixed_response = self._blend_response_content(assistant_msg.get('content', ''), mix_ratio)

        # Create augmented example
        augmented_example = {
            'messages': [
                {**user_msg, 'content': mixed_instruction},
                {**assistant_msg, 'content': mixed_response}
            ],
            'metadata': {
                **example.get('metadata', {}),
                'augmentation_type': 'self_mixup',
                'mix_ratio': mix_ratio,
                'original_vulnerability_id': example.get('metadata', {}).get('vulnerability_id', 'unknown')
            }
        }

        return augmented_example

    def _apply_semantic_variation(self, example: Dict[str, Any], variation_type: str) -> Optional[Dict[str, Any]]:
        """Apply semantic variation to create diverse training examples."""

        messages = example.get('messages', [])
        if not messages:
            return None

        # Apply semantic patterns to messages
        varied_messages = []
        for msg in messages:
            content = msg.get('content', '')
            varied_content = self._apply_semantic_patterns(content, variation_type)
            varied_messages.append({**msg, 'content': varied_content})

        # Create semantically varied example
        varied_example = {
            'messages': varied_messages,
            'metadata': {
                **example.get('metadata', {}),
                'augmentation_type': f'semantic_{variation_type}',
                'original_vulnerability_id': example.get('metadata', {}).get('vulnerability_id', 'unknown')
            }
        }

        return varied_example

    def _blend_instruction_content(self, instruction: str, mix_ratio: float) -> str:
        """Blend instruction content with WebAuthn-specific variations."""

        # Extract vulnerability type from instruction
        vuln_type = self._detect_vulnerability_type(instruction)

        if vuln_type and vuln_type in self.vulnerability_templates:
            # Get template variations for this vulnerability type
            templates = self.vulnerability_templates[vuln_type]
            selected_template = random.choice(templates)

            # Mix the instruction with template-based variation
            if 'vulnerability' in instruction.lower():
                mixed_instruction = instruction.replace(
                    instruction.split('\n')[0],  # Replace first line with mixed version
                    f"Analyze this {selected_template} and provide comprehensive analysis:"
                )
                return mixed_instruction

        return instruction  # Return original if no mixing possible

    def _blend_response_content(self, response: str, mix_ratio: float) -> str:
        """Blend response content with security-specific enhancements."""

        # Add variation to response structure while preserving core content
        lines = response.split('\n')
        if len(lines) > 3:
            # Vary the introduction
            if '# ' in lines[0]:
                original_title = lines[0]
                varied_title = original_title.replace('Analysis Report', 'Security Assessment')
                lines[0] = varied_title

        return '\n'.join(lines)

    def _apply_semantic_patterns(self, content: str, pattern_type: str) -> str:
        """Apply semantic patterns to vary content while preserving meaning."""

        if pattern_type not in self.semantic_patterns:
            return content

        patterns = self.semantic_patterns[pattern_type]
        varied_content = content

        # Apply random subset of patterns
        applied_patterns = random.sample(patterns, min(2, len(patterns)))

        for original, replacement in applied_patterns:
            # Case-insensitive replacement with word boundaries
            pattern = re.compile(r'\b' + re.escape(original) + r'\b', re.IGNORECASE)
            varied_content = pattern.sub(replacement, varied_content)

        return varied_content

    def _detect_vulnerability_type(self, text: str) -> Optional[str]:
        """Detect vulnerability type from text content."""

        text_lower = text.lower()

        # Detection patterns for different vulnerability types
        type_patterns = {
            'authentication': ['credential', 'session', 'origin', 'attestation', 'authentication'],
            'cryptographic': ['signature', 'key', 'entropy', 'certificate', 'cryptographic'],
            'configuration': ['cors', 'header', 'validation', 'transport', 'configuration'],
            'implementation': ['race', 'memory', 'error', 'state', 'implementation']
        }

        for vuln_type, keywords in type_patterns.items():
            if any(keyword in text_lower for keyword in keywords):
                return vuln_type

        return None

    def _group_by_vulnerability_type(self, examples: List[Dict[str, Any]]) -> Dict[str, List[Dict[str, Any]]]:
        """Group examples by detected vulnerability type."""

        grouped = {}

        for example in examples:
            # Try to detect type from user message
            messages = example.get('messages', [])
            user_content = ''

            for msg in messages:
                if msg.get('role') == 'user':
                    user_content = msg.get('content', '')
                    break

            vuln_type = self._detect_vulnerability_type(user_content) or 'general'

            if vuln_type not in grouped:
                grouped[vuln_type] = []

            grouped[vuln_type].append(example)

        return grouped

    def _create_context_blended_variants(self, examples: List[Dict[str, Any]], vuln_type: str) -> List[Dict[str, Any]]:
        """Create context-blended variants within the same vulnerability type."""

        variants = []

        # Create pairs for blending
        for i in range(min(3, len(examples) - 1)):  # Limit to 3 variants
            example1 = examples[i]
            example2 = examples[(i + 1) % len(examples)]

            try:
                blended = self._blend_two_examples(example1, example2, vuln_type)
                if blended:
                    variants.append(blended)
            except Exception as e:
                self.logger.warning(f"Failed to blend examples: {e}")
                continue

        return variants

    def _blend_two_examples(self, example1: Dict[str, Any], example2: Dict[str, Any], vuln_type: str) -> Optional[Dict[str, Any]]:
        """Blend two examples of the same vulnerability type."""

        # Extract content from both examples
        msg1 = self._extract_user_message(example1)
        msg2 = self._extract_user_message(example2)

        if not msg1 or not msg2:
            return None

        # Create blended instruction
        blended_instruction = f"Analyze this {vuln_type} vulnerability combining multiple attack vectors:\n\n"
        blended_instruction += f"Primary Vector: {msg1[:100]}...\n"
        blended_instruction += f"Secondary Vector: {msg2[:100]}...\n\n"
        blended_instruction += "Provide comprehensive analysis covering both vectors."

        # Use response from first example as base
        assistant_msg = self._extract_assistant_message(example1)

        if not assistant_msg:
            return None

        # Create blended example
        blended_example = {
            'messages': [
                {'role': 'user', 'content': blended_instruction},
                {'role': 'assistant', 'content': assistant_msg}
            ],
            'metadata': {
                **example1.get('metadata', {}),
                'augmentation_type': 'context_blending',
                'blended_vulnerability_types': [vuln_type],
                'source_examples': [
                    example1.get('metadata', {}).get('vulnerability_id', 'unknown'),
                    example2.get('metadata', {}).get('vulnerability_id', 'unknown')
                ]
            }
        }

        return blended_example

    def _extract_user_message(self, example: Dict[str, Any]) -> Optional[str]:
        """Extract user message content from example."""

        messages = example.get('messages', [])
        for msg in messages:
            if msg.get('role') == 'user':
                return msg.get('content', '')
        return None

    def _extract_assistant_message(self, example: Dict[str, Any]) -> Optional[str]:
        """Extract assistant message content from example."""

        messages = example.get('messages', [])
        for msg in messages:
            if msg.get('role') == 'assistant':
                return msg.get('content', '')
        return None

    def _ensure_quality_and_diversity(self, examples: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """Ensure quality and remove near-duplicates from augmented examples."""

        # Remove exact duplicates based on content similarity
        unique_examples = []
        seen_hashes = set()

        for example in examples:
            # Create simple content hash for deduplication
            content_hash = self._create_content_hash(example)

            if content_hash not in seen_hashes:
                seen_hashes.add(content_hash)
                unique_examples.append(example)

        self.logger.info(f"  ðŸ§¹ Quality filtering: {len(examples)} â†’ {len(unique_examples)} (removed {len(examples) - len(unique_examples)} duplicates)")

        return unique_examples

    def _create_content_hash(self, example: Dict[str, Any]) -> str:
        """Create a simple hash of example content for deduplication."""

        # Extract key content for hashing
        messages = example.get('messages', [])
        content_parts = []

        for msg in messages:
            role = msg.get('role', '')
            content = msg.get('content', '')[:100]  # First 100 chars
            content_parts.append(f"{role}:{content}")

        return hash('|'.join(content_parts))